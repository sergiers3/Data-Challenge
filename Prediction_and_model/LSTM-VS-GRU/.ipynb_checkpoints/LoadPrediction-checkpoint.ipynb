{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning:\n",
      "\n",
      "Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objs as go\n",
    "import plotly.plotly as py\n",
    "import plotly.offline as offline\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from pandas import read_csv\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, GRU\n",
    "from keras.layers import Dense\n",
    "from matplotlib import pyplot\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pumpNumber = \"4160\"\n",
    "dset = \"wet\"\n",
    "predict = \"level\"\n",
    "period = 1440\n",
    "\n",
    "dataset = read_csv(pumpNumber+ \"set\"+dset+\".csv\", header=0, index_col=0).iloc[::-1]\n",
    "#dataset = read_csv(\"/Users/sergiers/Desktop/Lieshout.csv\", header=0, index_col=0).iloc[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.sort_index(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = dataset.loc[:'2018-06-08 17:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(dset == \"wet\"):\n",
    "    dataset = dataset[[\"flow\", \"level\", \"WeekNumber\", \"DayOfWeek\", \"VOLUME\" ]]\n",
    "else:\n",
    "    dataset = dataset[[\"flow\", \"level\", \"WeekNumber\", \"DayOfWeek\" ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "flowstd = dataset[\"flow\"].std()\n",
    "flowmean = dataset[\"flow\"].mean()\n",
    "levelstd = dataset[\"level\"].mean()\n",
    "levelmean = dataset[\"level\"].std()\n",
    "\n",
    "flowmax = dataset.max()\n",
    "flowmin = dataset.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot origina data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file:///Users/sergiers/Desktop/NN/4160-level-wet-original.html'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "realdata = go.Scatter(\n",
    "          x=dataset.index,\n",
    "          y=dataset['flow'],\n",
    "          name='real')\n",
    "\n",
    "\n",
    "data = [realdata]\n",
    "\n",
    "\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='Original data',\n",
    "    xaxis=dict(\n",
    "        rangeselector=dict(\n",
    "            buttons=list([\n",
    "                dict(count=1,\n",
    "                     label='1d',\n",
    "                     step='day',\n",
    "                     stepmode='backward'),\n",
    "                dict(count=7,\n",
    "                     label='1w',\n",
    "                     step='day',\n",
    "                     stepmode='backward'),\n",
    "                dict(count=1,\n",
    "                     label='1m',\n",
    "                     step='month',\n",
    "                     stepmode='backward'),\n",
    "                dict(step='all')\n",
    "            ])\n",
    "        ),        \n",
    "        rangeslider=dict(\n",
    "            visible = True\n",
    "        ),\n",
    "        type='date'\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Real'\n",
    "    )\n",
    ")\n",
    "fig = dict(data=data, layout=layout)\n",
    "offline.plot(fig, filename=pumpNumber+\"-\"+predict+\"-\"+dset+\"-original.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing with Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset[dataset.columns] = StandardScaler().fit_transform(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shifting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# To avoid \"ValueError: Input arrays should have the same number of samples as target \n",
    "# arrays. Found 2095 input samples and 2090 target samples.\" error\n",
    "dataset_shifted = dataset.shift(-5)\n",
    "dataset = dataset.iloc[:-5]\n",
    "dataset_shifted = dataset_shifted.iloc[:-5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividing the Dataset for Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset.iloc[:-period]\n",
    "train_dataset_shifted = dataset_shifted.iloc[:-period]\n",
    "\n",
    "test_dataset = dataset.iloc[-period:]\n",
    "test_dataset_shifted = dataset_shifted.iloc[-period:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "237451/237451 [==============================] - 25s 104us/step - loss: 0.2381\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a217f9390>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lstm = Sequential()\n",
    "model_lstm.add(LSTM(1, input_shape=(1, dataset.shape[1])))\n",
    "model_lstm.add(Dense(1))\n",
    "model_lstm.compile(loss='mae', optimizer='adam')\n",
    "\n",
    "#model_lstm.fit(train_dataset.values.reshape((train_dataset.shape[0], 1, train_dataset.shape[1])), train_dataset_shifted['system.load.5'])\n",
    "model_lstm.fit(train_dataset.values.reshape((train_dataset.shape[0], 1, train_dataset.shape[1])), train_dataset_shifted[predict])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "237451/237451 [==============================] - 20s 84us/step - loss: 0.2083\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a1e6ef160>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gru = Sequential()\n",
    "model_gru.add(GRU(1, input_shape=(1, dataset.shape[1])))\n",
    "model_gru.add(Dense(1))\n",
    "model_gru.compile(loss='mae', optimizer='adam')\n",
    "\n",
    "model_gru.fit(train_dataset.values.reshape((train_dataset.shape[0], 1, train_dataset.shape[1])), train_dataset_shifted[predict])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_predicted_lstm = model_lstm.predict(test_dataset.values.reshape((test_dataset.shape[0], 1, test_dataset.shape[1])))\n",
    "test_dataset_predicted_gru = model_gru.predict(test_dataset.values.reshape((test_dataset.shape[0], 1, test_dataset.shape[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11067347361835835"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(test_dataset_shifted[predict], test_dataset_predicted_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10166559336008463"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(test_dataset_predicted_gru, test_dataset_shifted[predict])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### De-Shift:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame()\n",
    "lstm = pd.DataFrame()\n",
    "gru = pd.DataFrame()\n",
    "\n",
    "lstmtempArray = []\n",
    "for idx, val in enumerate(test_dataset_predicted_lstm):\n",
    "    lstmtempArray.append(val[0])\n",
    "    \n",
    "grutempArray = []\n",
    "for idx, val in enumerate(test_dataset_predicted_gru):\n",
    "    grutempArray.append(val[0])\n",
    "    \n",
    "lstm = pd.concat([pd.DataFrame([val], columns=['lstm']) for idx, val in enumerate(lstmtempArray)], ignore_index=True)\n",
    "gru = pd.concat([pd.DataFrame([val], columns=['gru']) for idx, val in enumerate(grutempArray)], ignore_index=True)\n",
    "\n",
    "result['real'] = test_dataset_shifted[predict]\n",
    "\n",
    "\n",
    "#deshift:\n",
    "lstm=lstm.iloc[5:]\n",
    "gru=gru.iloc[5:]\n",
    "result = result.iloc[:-5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recalculate error with deshifting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08215089739874844"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(result['real'], lstm[\"lstm\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.060379776388000655"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(gru[\"gru\"], result['real'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The error in the first 1 hours is 179.42 %\n",
      "The error in the first 2 hours is 161.39 %\n",
      "The error in the first 3 hours is 148.32 %\n",
      "The error in the first 6 hours is 117.16 %\n",
      "The error in the first 12 hours is 87.41 %\n",
      "The error in the first 24 hours is 65.69 %\n",
      "The error in the first 48 hours is 40.36 %\n",
      "The error in the first 72 hours is 28.63 %\n"
     ]
    }
   ],
   "source": [
    "def error_by_hour(test, predicted, test_type, hours ):\n",
    "    if (test_type not in ['flow','level']):\n",
    "        print(\"test_type must be either \\'flow\\' or \\'level\\'\")\n",
    "        return \n",
    "    test_dataset = test.reset_index()[test_type]\n",
    "    for hour in hours:\n",
    "        if hour > len(test_dataset) or hour > len(predicted):\n",
    "            break\n",
    "        error = float(0)\n",
    "        for i in range(0,hour):\n",
    "            error += np.abs((test_dataset[i] - predicted[i][0])/test_dataset[i])*100\n",
    "        error = error / hour\n",
    "        print(\"The error in the first \" + str(hour) + \" hours is %.2f %%\" % (error))\n",
    "\n",
    "error_by_hour(test_dataset_shifted, test_dataset_predicted_gru, 'level', [1,2,3,6,12,24,48,72])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot with normalized values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file:///Users/sergiers/Desktop/NN/4160-level-wet-normalized.html'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#FLOW\n",
    "#pyplot.plot(test_dataset_shifted[predict], label='real')\n",
    "\n",
    "#pyplot.plot(test_dataset_predicted_lstm, label='lstm')\n",
    "#pyplot.plot(test_dataset_predicted_gru, label='gru')\n",
    "#pyplot.legend()\n",
    "#pyplot.show()\n",
    "\n",
    "\n",
    "realdata = go.Scatter(\n",
    "          x=result.index,\n",
    "          y=result['real'],\n",
    "          name='real')\n",
    "\n",
    "lstmdata = go.Scatter(\n",
    "          x=result.index,\n",
    "          y=lstm[\"lstm\"],\n",
    "          name='lstm',\n",
    "          yaxis='y2')\n",
    "\n",
    "grudata = go.Scatter(\n",
    "          x=result.index,\n",
    "          y=gru[\"gru\"],\n",
    "          name='gru',\n",
    "          yaxis='y2')\n",
    "\n",
    "\n",
    "data = [realdata,lstmdata,grudata]\n",
    "\n",
    "\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='Prediction error normalized',\n",
    "    xaxis=dict(\n",
    "        rangeselector=dict(\n",
    "            buttons=list([\n",
    "                dict(count=1,\n",
    "                     label='1d',\n",
    "                     step='day',\n",
    "                     stepmode='backward'),\n",
    "                dict(count=7,\n",
    "                     label='1w',\n",
    "                     step='day',\n",
    "                     stepmode='backward'),\n",
    "                dict(count=1,\n",
    "                     label='1m',\n",
    "                     step='month',\n",
    "                     stepmode='backward'),\n",
    "                dict(step='all')\n",
    "            ])\n",
    "        ),        \n",
    "        rangeslider=dict(\n",
    "            visible = True\n",
    "        ),\n",
    "        type='date'\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Real'\n",
    "    ),\n",
    "    yaxis2=dict(\n",
    "        title='Lstm',\n",
    "        overlaying='y',\n",
    "        side='right'\n",
    "    ),\n",
    "    yaxis3=dict(\n",
    "        title='Gru',\n",
    "        overlaying='y',\n",
    "        side='right'\n",
    "    )\n",
    ")\n",
    "fig = dict(data=data, layout=layout)\n",
    "offline.plot(fig, filename=pumpNumber+\"-\"+predict+\"-\"+dset+\"-normalized.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Denormalize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Denormalize\n",
    "\n",
    "result[\"real\"] = result[\"real\"]*flowstd + flowmean\n",
    "#test_dataset_shifted[\"level\"] = test_dataset_shifted[\"level\"]*flowstd + flowmean\n",
    "\n",
    "lstm[\"lstm\"] = lstm[\"lstm\"]*flowstd + flowmean\n",
    "#test_dataset_predicted_lstm[\"level\"] = test_dataset_predicted_lstm[\"level\"]*flowstd + flowmean\n",
    "\n",
    "gru[\"gru\"] = gru[\"gru\"]*flowstd + flowmean\n",
    "#test_dataset_predicted_gru[\"level\"] = test_dataset_predicted_gru[\"level\"]*flowstd + flowmean\n",
    "\n",
    "#fix negative problem:\n",
    "result[\"real\"] = np.where(result[\"real\"]<0, 0, result[\"real\"])\n",
    "lstm[\"lstm\"] = np.where(lstm[\"lstm\"]<0, 0, lstm[\"lstm\"])\n",
    "gru[\"gru\"] = np.where(gru[\"gru\"]<0, 0, gru[\"gru\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recalculate error with de-normalization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4502131159452367"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(result['real'], lstm[\"lstm\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3231238201193488"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(gru[\"gru\"], result['real'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file:///Users/sergiers/Desktop/NN/4160-level-wet-real.html'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "realdata = go.Scatter(\n",
    "          x=result.index,\n",
    "          y=result['real'],\n",
    "          name='real')\n",
    "\n",
    "lstmdata = go.Scatter(\n",
    "          x=result.index,\n",
    "          y=lstm[\"lstm\"],\n",
    "          name='lstm',\n",
    "          yaxis='y2')\n",
    "\n",
    "grudata = go.Scatter(\n",
    "          x=result.index,\n",
    "          y=gru[\"gru\"],\n",
    "          name='gru',\n",
    "          yaxis='y2')\n",
    "\n",
    "\n",
    "data = [realdata,lstmdata,grudata]\n",
    "\n",
    "\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='Prediction error (real values)',\n",
    "    xaxis=dict(\n",
    "        rangeselector=dict(\n",
    "            buttons=list([\n",
    "                dict(count=1,\n",
    "                     label='1d',\n",
    "                     step='day',\n",
    "                     stepmode='backward'),\n",
    "                dict(count=7,\n",
    "                     label='1w',\n",
    "                     step='day',\n",
    "                     stepmode='backward'),\n",
    "                dict(count=1,\n",
    "                     label='1m',\n",
    "                     step='month',\n",
    "                     stepmode='backward'),\n",
    "                dict(step='all')\n",
    "            ])\n",
    "        ),        \n",
    "        rangeslider=dict(\n",
    "            visible = True\n",
    "        ),\n",
    "        type='date'\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Real'\n",
    "    ),\n",
    "    yaxis2=dict(\n",
    "        title='Lstm',\n",
    "        overlaying='y',\n",
    "        side='right'\n",
    "    ),\n",
    "    yaxis3=dict(\n",
    "        title='Gru',\n",
    "        overlaying='y',\n",
    "        side='right'\n",
    "    )\n",
    ")\n",
    "fig = dict(data=data, layout=layout)\n",
    "offline.plot(fig, filename=pumpNumber+\"-\"+predict+\"-\"+dset+\"-real.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Optimal Paramers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from sklearn.model_selection import GridSearchCV\\nfrom keras.wrappers.scikit_learn import KerasClassifier\\nimport copy\\n\\ndef fit_lstm_tuning(activation, recurrent_activation, loss, optimizer):\\n    model_lstm = Sequential()\\n    model_lstm.add(LSTM(1, input_shape=(1, dataset.shape[1]), activation = activation, recurrent_activation = recurrent_activation))\\n    model_lstm.add(Dense(1))\\n    model_lstm.compile(loss=loss, optimizer=optimizer, metrics=[\"accuracy\"])\\n    return model_lstm\\n\\nactivations = [\\'softmax\\', \\'elu\\', \\'selu\\', \\'softplus\\', \\'softsign\\', \\'relu\\', \\'tanh\\', \\'sigmoid\\', \\'hard_sigmoid\\', \\'linear\\']\\nrecurrent_activations = [\\'softmax\\', \\'elu\\', \\'selu\\', \\'softplus\\', \\'softsign\\', \\'relu\\', \\'tanh\\', \\'sigmoid\\', \\'hard_sigmoid\\', \\'linear\\']\\n\\noptimizers = [\\'SGD\\', \\'RMSprop\\', \\'Adagrad\\', \\'Adadelta\\', \\'Adam\\', \\'Adamax\\', \\'Nadam\\']\\nlosses = [\\'mean_squared_error\\', \\'mean_absolute_error\\', \\'mean_absolute_percentage_error\\', \\'mean_squared_logarithmic_error\\', \\'squared_hinge\\', \\'hinge\\', \\'categorical_hinge\\', \\'logcosh\\', \\'categorical_crossentropy\\', \\'sparse_categorical_crossentropy\\', \\'binary_crossentropy\\', \\'kullback_leibler_divergence\\', \\'poisson\\', \\'cosine_proximity\\']\\n\\nX = copy.deepcopy(train_dataset.values.reshape((train_dataset.shape[0], 1, train_dataset.shape[1])))\\nY = copy.deepcopy(train_dataset_shifted[\\'flow\\'])\\n\\nmodel = KerasClassifier(build_fn=fit_lstm_tuning)\\n\\nparam_grid = dict(activation = activations, recurrent_activation = recurrent_activations, optimizer = optimizers, loss = losses)\\n\\ngrid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\\ngrid_result = grid.fit(X,Y)\\n\\nprint(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import copy\n",
    "\n",
    "def fit_lstm_tuning(activation, recurrent_activation, loss, optimizer):\n",
    "    model_lstm = Sequential()\n",
    "    model_lstm.add(LSTM(1, input_shape=(1, dataset.shape[1]), activation = activation, recurrent_activation = recurrent_activation))\n",
    "    model_lstm.add(Dense(1))\n",
    "    model_lstm.compile(loss=loss, optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "    return model_lstm\n",
    "\n",
    "activations = ['softmax', 'elu', 'selu', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "recurrent_activations = ['softmax', 'elu', 'selu', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "\n",
    "optimizers = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "losses = ['mean_squared_error', 'mean_absolute_error', 'mean_absolute_percentage_error', 'mean_squared_logarithmic_error', 'squared_hinge', 'hinge', 'categorical_hinge', 'logcosh', 'categorical_crossentropy', 'sparse_categorical_crossentropy', 'binary_crossentropy', 'kullback_leibler_divergence', 'poisson', 'cosine_proximity']\n",
    "\n",
    "X = copy.deepcopy(train_dataset.values.reshape((train_dataset.shape[0], 1, train_dataset.shape[1])))\n",
    "Y = copy.deepcopy(train_dataset_shifted['flow'])\n",
    "\n",
    "model = KerasClassifier(build_fn=fit_lstm_tuning)\n",
    "\n",
    "param_grid = dict(activation = activations, recurrent_activation = recurrent_activations, optimizer = optimizers, loss = losses)\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
    "grid_result = grid.fit(X,Y)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
